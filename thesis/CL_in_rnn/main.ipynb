{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.manual_seed(4)\n",
    "np.random.seed(4)\n",
    "\n",
    "def create_dataset_1(n):\n",
    "    X,Y = [],[]\n",
    "    for _ in range(2000):\n",
    "        r = np.random.randint(2,n)\n",
    "        x = np.random.uniform(0,1,size=(2,r))\n",
    "        x2 = np.zeros(r)\n",
    "        x2[0:2] = 1\n",
    "        x[1,:] = np.random.permutation(x2)\n",
    "        X.append(x)\n",
    "        Y.append(np.dot(x[0,:],x[1,:]))\n",
    "    return X,Y\n",
    "\n",
    "\n",
    "def create_dataset_2(n):\n",
    "    X,Y = [],[]\n",
    "    for _ in range(2000):\n",
    "        r = np.random.randint(2,n)\n",
    "        x = np.random.uniform(0,1,size=(2,r))\n",
    "        x2 = np.zeros(r)\n",
    "        x2[0] = 1\n",
    "        x2[1] = -1\n",
    "        x[1,:] = np.random.permutation(x2)\n",
    "        X.append(x)\n",
    "        Y.append(np.dot(x[0,:],x[1,:]))\n",
    "        Y.append(np.sum(2*x[0,:]+5*x[1,:]))\n",
    "    return X,Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gru(nn.Module):\n",
    "    def __init__(self, ins, hs, os):\n",
    "        super(gru, self).__init__()\n",
    "        self.hs = hs\n",
    "        self.wz = nn.Linear(ins + hs,hs)\n",
    "        self.wr = nn.Linear(ins + hs,hs)\n",
    "        self.wh = nn.Linear(ins + hs,hs)\n",
    "        self.hy = nn.Linear(hs,os)\n",
    "\n",
    "    def Sigmoid(self,x):\n",
    "        return 1/(1+t.exp(-1*x))\n",
    "\n",
    "    def init_hidden(self):\n",
    "        self.h = t.zeros(1,self.hs)\n",
    "\n",
    "    def forward_one_pair(self,x):\n",
    "        ip = t.cat((x,self.h),1)\n",
    "        z = self.Sigmoid(self.wz(ip))\n",
    "        r = self.Sigmoid(self.wr(ip))\n",
    "        ip1 = t.cat((x,r*self.h),1)\n",
    "        h1 = t.tanh(self.wh(ip1))\n",
    "        self.h = (1-z)*self.h + z*h1\n",
    "        output = self.hy(self.h)\n",
    "        return output\n",
    "    \n",
    "    def forward(self,x):\n",
    "        self.init_hidden()\n",
    "        for a in range(x.shape[1]):\n",
    "            output = self.forward_one_pair(x.T[a].reshape(1,2))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,optimizer,loss_fn,xtrain,ytrain,epochs):\n",
    "    res_array = []\n",
    "    for i in range(epochs):\n",
    "        loss1 = 0\n",
    "        net.train()\n",
    "        for x,y in zip(xtrain,ytrain):\n",
    "            optimizer.zero_grad()\n",
    "            X = t.tensor(x).to(t.float32)\n",
    "            Y = t.tensor(y).to(t.float32)\n",
    "            output = net(X).squeeze(0)\n",
    "            loss = loss_fn(output,Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss1 += loss.item()\n",
    "        res_array.append(loss1)\n",
    "        print(f\"Training loss at iteration {i} is {loss1/len(ytrain)}\")\n",
    "    return net,res_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(net,xtest,ytest):\n",
    "    ypred = []\n",
    "    for a in xtest:\n",
    "        a = t.tensor(a).to(t.float32)\n",
    "        u = net(a).squeeze(0).item()\n",
    "        ypred.append(u)\n",
    "    ypred = np.array(ypred)\n",
    "    return round(((abs(ypred-ytest)<=0.017).sum() / len(ypred))*100,4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = create_dataset_1(9)\n",
    "X1,Y1 = create_dataset_2(9)\n",
    "xtrain,xtest,ytrain,ytest=tts(X,Y,random_state=42,test_size=0.15,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nk/.conda/envs/code/lib/python3.11/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0 is 0.08346007551101546\n",
      "Training loss at iteration 1 is 0.003949735951300922\n",
      "Training loss at iteration 2 is 0.0007280590762217124\n",
      "Training loss at iteration 3 is 0.00047562723286135087\n",
      "Training loss at iteration 4 is 0.0005031030432972685\n",
      "Training loss at iteration 5 is 0.0005033874159442866\n",
      "Training loss at iteration 6 is 0.0004829774015939638\n",
      "Training loss at iteration 7 is 0.0004591281831692071\n",
      "Training loss at iteration 8 is 0.0004354198530231024\n",
      "Training loss at iteration 9 is 0.0004128205137806371\n",
      "Training loss at iteration 10 is 0.00039204789733066504\n",
      "Training loss at iteration 11 is 0.0003738377144406153\n",
      "Training loss at iteration 12 is 0.000358460727495728\n",
      "Training loss at iteration 13 is 0.0003457319035981269\n",
      "Training loss at iteration 14 is 0.00033528869840021217\n"
     ]
    }
   ],
   "source": [
    "t.manual_seed(4)\n",
    "np.random.seed(4)\n",
    "\n",
    "epochs = 15\n",
    "net1 = gru(2,6,1)\n",
    "optimizer1 = t.optim.Adam(net1.parameters(),lr=0.005)\n",
    "loss_fn1 = t.nn.MSELoss()\n",
    "net1,res_array1 = train(net1,optimizer1,loss_fn1,xtrain,ytrain,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on testing data for GRU is 91.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"The Accuracy on testing data for GRU is {accuracy(net1,xtest,ytest)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain1,xtest1,ytrain1,ytest1=tts(X1,Y1,random_state=42,test_size=0.15,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
